{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.2659077] [ 0.2889584]\n",
      "20 [ 0.12912342] [ 0.28411582]\n",
      "40 [ 0.10640077] [ 0.29650897]\n",
      "60 [ 0.10140677] [ 0.29923275]\n",
      "80 [ 0.10030919] [ 0.29983139]\n",
      "100 [ 0.10006796] [ 0.29996294]\n",
      "120 [ 0.10001494] [ 0.29999188]\n",
      "140 [ 0.10000329] [ 0.29999822]\n",
      "160 [ 0.10000071] [ 0.29999962]\n",
      "180 [ 0.10000015] [ 0.29999992]\n",
      "200 [ 0.10000009] [ 0.29999995]\n"
     ]
    }
   ],
   "source": [
    "#利用梯度遞減（Gradient descent）的演算法找出已知迴歸模型（y = 0.1x + 0.3）的係數（0.1）與截距（0.3）並對照結果\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# W 指的是係數，斜率介於 -1 至 1 之間\n",
    "# b 指的是截距，從 0 開始逼近任意數字\n",
    "# y 指的是預測值\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# 我們的目標是要讓 loss（MSE）最小化\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 將神經網絡圖畫出來\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 將迴歸線的係數與截距模擬出來\n",
    "# 每跑 20 次把當時的係數與截距印出來\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "        \n",
    "# 關閉 Session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 名詞 \t定義\n",
    "# Graphs    \t建立運算元\n",
    "# Sessions  \t執行運算\n",
    "# Tensors   \t資料\n",
    "# Variables \t變數\n",
    "# Feeds     \t資料輸入\n",
    "# Fetches   \t資料輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_1:0' shape=(1, 1) dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立運算元\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1x2 的矩陣\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "\n",
    "# 2x1 的矩陣\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]]\n",
    "                     )\n",
    "\n",
    "# matmul() 方法代表是矩陣的乘法，答案是 12\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# 執行運算 , method 1\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1x2 的矩陣\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "\n",
    "# 2x1 的矩陣\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]]\n",
    "                      )\n",
    "\n",
    "# matmul() 方法代表是矩陣的乘法\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# 啟動 Session\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "\n",
    "# 關閉 Session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[12]])]\n"
     ]
    }
   ],
   "source": [
    "# 執行運算 , method 2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1x2 的矩陣\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "\n",
    "# 2x1 的矩陣\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]]\n",
    "                      )\n",
    "\n",
    "# matmul() 方法代表是矩陣的乘法\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# 啟動\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([product])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# 啟動 Session, method 3\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1x2 的矩陣\n",
    "# 注意這裡改變成 Variable\n",
    "matrix1 = tf.Variable([[3, 3]])\n",
    "\n",
    "# 2x1 的矩陣\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]]\n",
    "                      )\n",
    "\n",
    "# 初始化 `matrix1`\n",
    "matrix1.initializer.run()\n",
    "\n",
    "# 執行運算\n",
    "result = tf.matmul(matrix1, matrix2)\n",
    "print(result.eval())\n",
    "\n",
    "# 關閉 Session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#變數\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 建立 Variable\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# 每次加 1 之後更新 state\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# 初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 執行運算\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # 印初始值\n",
    "    print(sess.run(state))\n",
    "    # 更新三次分別印出 Variable\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))\n",
    "        \n",
    "# 關閉 Session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 21.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#資料輸入\n",
    "#先利用 tf.placeholder() 宣告資料的種類，在執行的時候才將資料以字典（dictionary）的結構輸入。\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "# 將 input1 以 7 輸入，input2 以 3 輸入\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict = {input1: [7], input2: [3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([8]), array([15])]\n"
     ]
    }
   ],
   "source": [
    "#資料輸出\n",
    "\n",
    "input1 = tf.constant([3])\n",
    "input2 = tf.constant([5])\n",
    "added = tf.add(input1, input2)\n",
    "multiplied = tf.multiply(input1, input2)\n",
    "\n",
    "# 輸出 added 與 multiplied\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([added, multiplied])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "#一直提到的建立運算元（Graphs）究竟在哪裡？是看得到的嗎？答案是可以的，我們可以利用 TensorBoard 來視覺化神經網絡\n",
    "\n",
    "#定義一個添加層的函數：add_layer()\n",
    "#準備資料（Inputs）\n",
    "#建立 Feeds（使用 tf.placeholder() 方法）來傳入資料\n",
    "#添加隱藏層與輸出層\n",
    "#定義 loss 與要使用的 Optimizer（使用梯度遞減）\n",
    "#初始化 Graph 並開始運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34202\n",
      "0.00219888\n",
      "0.00116119\n",
      "0.00061362\n",
      "0.000324308\n",
      "0.000171421\n",
      "9.06156e-05\n",
      "4.79026e-05\n",
      "2.53234e-05\n",
      "1.33871e-05\n",
      "7.07656e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定義一個添加層的函數\n",
    "def add_layer(inputs, input_tensors, output_tensors, activation_function = None):\n",
    "    W = tf.Variable(tf.random_normal([input_tensors, output_tensors]))\n",
    "    b = tf.Variable(tf.zeros([1, output_tensors]))\n",
    "    formula = tf.add(tf.matmul(inputs, W), b)\n",
    "    if activation_function is None:\n",
    "        outputs = formula\n",
    "    else:\n",
    "        outputs = activation_function(formula)\n",
    "    return outputs\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立 Feeds\n",
    "x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 添加 1 個隱藏層\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1, output_tensors = 10, activation_function = None)\n",
    "\n",
    "# 添加 1 個輸出層\n",
    "output_layer = add_layer(hidden_layer, input_tensors = 10, output_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化 Graph 並開始運算\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#視覺化\n",
    "#接著我們要在模組化的程式中使用 with tf.name_scope(): 為每個運算元命名，然後在神經網絡運算初始之後，\n",
    "#利用 tf.summary.FileWriter() 將視覺化檔案輸出。\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定義一個添加層的函數\n",
    "def add_layer(inputs, input_tensors, output_tensors, activation_function = None):\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            W = tf.Variable(tf.random_normal([input_tensors, output_tensors]))\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, output_tensors]))\n",
    "        with tf.name_scope('Formula'):\n",
    "            formula = tf.add(tf.matmul(inputs, W), b)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        return outputs\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 添加 1 個隱藏層\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1, output_tensors = 10, activation_function = None)\n",
    "\n",
    "# 添加 1 個輸出層\n",
    "output_layer = add_layer(hidden_layer, input_tensors = 10, output_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化 Graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "# 將視覺化輸出\n",
    "writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "# 開始運算\n",
    "sess.run(init)\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    #if step % 20 == 0:\n",
    "        #print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#我們除了可以使用 with tf.name_scope(): 為每個運算元命名，我們還可以在使用 tf.Variable() 或者 tf.placeholder() 建立變數或輸入資料時，\n",
    "#利用 name = 參數進行命名。\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定義一個添加層的函數\n",
    "def add_layer(inputs, input_tensors, output_tensors, activation_function = None):\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            W = tf.Variable(tf.random_normal([input_tensors, output_tensors]), name = 'W')\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, output_tensors]), name = 'b')\n",
    "        with tf.name_scope('Formula'):\n",
    "            formula = tf.add(tf.matmul(inputs, W), b)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        return outputs\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'x_inputs')\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'y_inputs')\n",
    "\n",
    "# 添加 1 個隱藏層\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1, output_tensors = 10, activation_function = None)\n",
    "\n",
    "# 添加 1 個輸出層\n",
    "output_layer = add_layer(hidden_layer, input_tensors = 10, output_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化 Graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "# 將視覺化輸出\n",
    "writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "# 開始運算\n",
    "sess.run(init)\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    #if step % 20 == 0:\n",
    "        #print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
