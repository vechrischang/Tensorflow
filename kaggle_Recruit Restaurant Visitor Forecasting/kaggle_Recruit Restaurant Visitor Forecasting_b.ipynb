{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, re\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('air_visit_data.csv', error_bad_lines=False),\n",
    "    'as': pd.read_csv('air_store_info.csv', error_bad_lines=False),\n",
    "    'ar': pd.read_csv('air_reserve.csv', error_bad_lines=False),\n",
    "    \n",
    "    'hs': pd.read_csv('hpg_store_info.csv', error_bad_lines=False),\n",
    "    'hr': pd.read_csv('hpg_reserve.csv', error_bad_lines=False),\n",
    "    \n",
    "    'id': pd.read_csv('store_id_relation.csv', error_bad_lines=False),\n",
    "    'tes': pd.read_csv('sample_submission.csv', error_bad_lines=False),\n",
    "    'hol': pd.read_csv('date_info.csv', error_bad_lines=False).rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date format\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    # duration between vist and res time\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new metrics\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow\n",
       "0  air_00a91d42b08b08d9    0\n",
       "1  air_0164b9927d20bcc3    0\n",
       "2  air_0241aa3964b7f861    0\n",
       "3  air_0328696196e46f18    0\n",
       "4  air_034a3d5b40d5b1b1    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df - stores\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō-to Taitō-ku Higashiueno</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Nakanochō</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>135.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.864865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Cafe/Sweets</td>\n",
       "      <td>Ōsaka-fu Ōsaka-shi Ōhiraki</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>135.472229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "3  air_0328696196e46f18    0           2.0       6.416667              4.0   \n",
       "4  air_034a3d5b40d5b1b1    0           1.0      11.864865             10.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  \\\n",
       "0          47.0                35.0  Italian/French   \n",
       "1          19.0                20.0  Italian/French   \n",
       "2          23.0                63.0         Izakaya   \n",
       "3          27.0                12.0      Dining bar   \n",
       "4          66.0                37.0     Cafe/Sweets   \n",
       "\n",
       "                     air_area_name   latitude   longitude  \n",
       "0  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \n",
       "1     Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599  \n",
       "2    Tōkyō-to Taitō-ku Higashiueno  35.712607  139.779996  \n",
       "3     Ōsaka-fu Ōsaka-shi Nakanochō  34.701279  135.528090  \n",
       "4       Ōsaka-fu Ōsaka-shi Ōhiraki  34.692337  135.472229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group data by id & days_of_week, compute mean etc...\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "# merge with store info\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id'])\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italian French</td>\n",
       "      <td>Tōkyō to Chiyoda ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Italian French</td>\n",
       "      <td>Tōkyō to Minato ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Izakaya</td>\n",
       "      <td>Tōkyō to Taitō ku Higashiueno</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Ōsaka fu Ōsaka shi Nakanochō</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>135.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.864865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Cafe Sweets</td>\n",
       "      <td>Ōsaka fu Ōsaka shi Ōhiraki</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>135.472229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "3  air_0328696196e46f18    0           2.0       6.416667              4.0   \n",
       "4  air_034a3d5b40d5b1b1    0           1.0      11.864865             10.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  \\\n",
       "0          47.0                35.0  Italian French   \n",
       "1          19.0                20.0  Italian French   \n",
       "2          23.0                63.0         Izakaya   \n",
       "3          27.0                12.0      Dining bar   \n",
       "4          66.0                37.0     Cafe Sweets   \n",
       "\n",
       "                     air_area_name   latitude   longitude  \n",
       "0  Tōkyō to Chiyoda ku Kudanminami  35.694003  139.753595  \n",
       "1     Tōkyō to Minato ku Shibakōen  35.658068  139.751599  \n",
       "2    Tōkyō to Taitō ku Higashiueno  35.712607  139.779996  \n",
       "3     Ōsaka fu Ōsaka shi Nakanochō  34.701279  135.528090  \n",
       "4       Ōsaka fu Ōsaka shi Ōhiraki  34.692337  135.472229  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map features\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name5</th>\n",
       "      <th>air_area_name5</th>\n",
       "      <th>air_genre_name6</th>\n",
       "      <th>air_area_name6</th>\n",
       "      <th>air_genre_name7</th>\n",
       "      <th>air_area_name7</th>\n",
       "      <th>air_genre_name8</th>\n",
       "      <th>air_area_name8</th>\n",
       "      <th>air_genre_name9</th>\n",
       "      <th>air_area_name9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.864865</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "3  air_0328696196e46f18    0           2.0       6.416667              4.0   \n",
       "4  air_034a3d5b40d5b1b1    0           1.0      11.864865             10.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  air_area_name   latitude  \\\n",
       "0          47.0                35.0               6             44  35.694003   \n",
       "1          19.0                20.0               6             62  35.658068   \n",
       "2          23.0                63.0               7             82  35.712607   \n",
       "3          27.0                12.0               4             98  34.701279   \n",
       "4          66.0                37.0               2            102  34.692337   \n",
       "\n",
       "        ...        air_genre_name5  air_area_name5  air_genre_name6  \\\n",
       "0       ...                      0               0                0   \n",
       "1       ...                      0               0                0   \n",
       "2       ...                      0               0                0   \n",
       "3       ...                      0               0                0   \n",
       "4       ...                      0               0                0   \n",
       "\n",
       "   air_area_name6  air_genre_name7  air_area_name7  air_genre_name8  \\\n",
       "0               0                0               0                0   \n",
       "1               0                0               0                0   \n",
       "2               0                0               0                0   \n",
       "3               0                0               0                0   \n",
       "4               0                0               0                0   \n",
       "\n",
       "   air_area_name8  air_genre_name9  air_area_name9  \n",
       "0               0                0               0  \n",
       "1               0                0               0  \n",
       "2               0                0               0  \n",
       "3               0                0               0  \n",
       "4               0                0               0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using labelencoder() for stories\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) \n",
    "\tif len(str(x).split(' '))>i \n",
    "\telse ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) \n",
    "\tif len(str(x).split(' '))>i \n",
    "\telse ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data hol\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name5</th>\n",
       "      <th>air_area_name5</th>\n",
       "      <th>air_genre_name6</th>\n",
       "      <th>air_area_name6</th>\n",
       "      <th>air_genre_name7</th>\n",
       "      <th>air_area_name7</th>\n",
       "      <th>air_genre_name8</th>\n",
       "      <th>air_area_name8</th>\n",
       "      <th>air_genre_name9</th>\n",
       "      <th>air_area_name9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14 00:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15 00:00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id           visit_date  visitors  dow  year  month  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13 00:00:00        25    2  2016      1   \n",
       "1  air_ba937bf13d40fb24  2016-01-14 00:00:00        32    3  2016      1   \n",
       "2  air_ba937bf13d40fb24  2016-01-15 00:00:00        29    4  2016      1   \n",
       "3  air_ba937bf13d40fb24  2016-01-16 00:00:00        22    5  2016      1   \n",
       "4  air_ba937bf13d40fb24  2016-01-18 00:00:00         6    0  2016      1   \n",
       "\n",
       "   day_of_week  holiday_flg  min_visitors  mean_visitors       ...        \\\n",
       "0          NaN          NaN           7.0      23.843750       ...         \n",
       "1          NaN          NaN           2.0      20.292308       ...         \n",
       "2          NaN          NaN           4.0      34.738462       ...         \n",
       "3          NaN          NaN           6.0      27.651515       ...         \n",
       "4          NaN          NaN           2.0      13.754386       ...         \n",
       "\n",
       "   air_genre_name5  air_area_name5  air_genre_name6  air_area_name6  \\\n",
       "0              0.0             0.0              0.0             0.0   \n",
       "1              0.0             0.0              0.0             0.0   \n",
       "2              0.0             0.0              0.0             0.0   \n",
       "3              0.0             0.0              0.0             0.0   \n",
       "4              0.0             0.0              0.0             0.0   \n",
       "\n",
       "   air_genre_name7  air_area_name7  air_genre_name8  air_area_name8  \\\n",
       "0              0.0             0.0              0.0             0.0   \n",
       "1              0.0             0.0              0.0             0.0   \n",
       "2              0.0             0.0              0.0             0.0   \n",
       "3              0.0             0.0              0.0             0.0   \n",
       "4              0.0             0.0              0.0             0.0   \n",
       "\n",
       "   air_genre_name9  air_area_name9  \n",
       "0              0.0             0.0  \n",
       "1              0.0             0.0  \n",
       "2              0.0             0.0  \n",
       "3              0.0             0.0  \n",
       "4              0.0             0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test by tra+hol+stores\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name9</th>\n",
       "      <th>air_area_name9</th>\n",
       "      <th>rs1_x</th>\n",
       "      <th>rv1_x</th>\n",
       "      <th>rs2_x</th>\n",
       "      <th>rv2_x</th>\n",
       "      <th>rs1_y</th>\n",
       "      <th>rv1_y</th>\n",
       "      <th>rs2_y</th>\n",
       "      <th>rv2_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14 00:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15 00:00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id           visit_date  visitors  dow  year  month  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13 00:00:00        25    2  2016      1   \n",
       "1  air_ba937bf13d40fb24  2016-01-14 00:00:00        32    3  2016      1   \n",
       "2  air_ba937bf13d40fb24  2016-01-15 00:00:00        29    4  2016      1   \n",
       "3  air_ba937bf13d40fb24  2016-01-16 00:00:00        22    5  2016      1   \n",
       "4  air_ba937bf13d40fb24  2016-01-18 00:00:00         6    0  2016      1   \n",
       "\n",
       "   day_of_week  holiday_flg  min_visitors  mean_visitors  ...    \\\n",
       "0          NaN          NaN           7.0      23.843750  ...     \n",
       "1          NaN          NaN           2.0      20.292308  ...     \n",
       "2          NaN          NaN           4.0      34.738462  ...     \n",
       "3          NaN          NaN           6.0      27.651515  ...     \n",
       "4          NaN          NaN           2.0      13.754386  ...     \n",
       "\n",
       "   air_genre_name9  air_area_name9  rs1_x  rv1_x  rs2_x  rv2_x  rs1_y  rv1_y  \\\n",
       "0              0.0             0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1              0.0             0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2              0.0             0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3              0.0             0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4              0.0             0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   rs2_y  rv2_y  \n",
       "0    NaN    NaN  \n",
       "1    NaN    NaN  \n",
       "2    NaN    NaN  \n",
       "3    NaN    NaN  \n",
       "4    NaN    NaN  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>rs2_x</th>\n",
       "      <th>rv2_x</th>\n",
       "      <th>rs1_y</th>\n",
       "      <th>rv1_y</th>\n",
       "      <th>rs2_y</th>\n",
       "      <th>rv2_y</th>\n",
       "      <th>id</th>\n",
       "      <th>total_reserv_sum</th>\n",
       "      <th>total_reserv_mean</th>\n",
       "      <th>total_reserv_dt_diff_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14 00:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15 00:00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id           visit_date  visitors  dow  year  month  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13 00:00:00        25    2  2016      1   \n",
       "1  air_ba937bf13d40fb24  2016-01-14 00:00:00        32    3  2016      1   \n",
       "2  air_ba937bf13d40fb24  2016-01-15 00:00:00        29    4  2016      1   \n",
       "3  air_ba937bf13d40fb24  2016-01-16 00:00:00        22    5  2016      1   \n",
       "4  air_ba937bf13d40fb24  2016-01-18 00:00:00         6    0  2016      1   \n",
       "\n",
       "   day_of_week  holiday_flg  min_visitors  mean_visitors  \\\n",
       "0          NaN          NaN           7.0      23.843750   \n",
       "1          NaN          NaN           2.0      20.292308   \n",
       "2          NaN          NaN           4.0      34.738462   \n",
       "3          NaN          NaN           6.0      27.651515   \n",
       "4          NaN          NaN           2.0      13.754386   \n",
       "\n",
       "             ...              rs2_x  rv2_x  rs1_y  rv1_y  rs2_y  rv2_y  \\\n",
       "0            ...                NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1            ...                NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2            ...                NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3            ...                NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4            ...                NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "                                         id  total_reserv_sum  \\\n",
       "0  air_ba937bf13d40fb24_2016-01-13 00:00:00               NaN   \n",
       "1  air_ba937bf13d40fb24_2016-01-14 00:00:00               NaN   \n",
       "2  air_ba937bf13d40fb24_2016-01-15 00:00:00               NaN   \n",
       "3  air_ba937bf13d40fb24_2016-01-16 00:00:00               NaN   \n",
       "4  air_ba937bf13d40fb24_2016-01-18 00:00:00               NaN   \n",
       "\n",
       "   total_reserv_mean  total_reserv_dt_diff_mean  \n",
       "0                NaN                        NaN  \n",
       "1                NaN                        NaN  \n",
       "2                NaN                        NaN  \n",
       "3                NaN                        NaN  \n",
       "4                NaN                        NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combin two cols as id\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>rv2_y</th>\n",
       "      <th>id</th>\n",
       "      <th>total_reserv_sum</th>\n",
       "      <th>total_reserv_mean</th>\n",
       "      <th>total_reserv_dt_diff_mean</th>\n",
       "      <th>date_int</th>\n",
       "      <th>var_max_lat</th>\n",
       "      <th>var_max_long</th>\n",
       "      <th>lon_plus_lat</th>\n",
       "      <th>air_store_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13 00:00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160113</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>175.409667</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14 00:00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160114</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>175.409667</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15 00:00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160115</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>175.409667</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16 00:00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160116</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>175.409667</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18 00:00:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>20160118</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>175.409667</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors  dow  year  month  day_of_week  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13        25    2  2016      1         -1.0   \n",
       "1  air_ba937bf13d40fb24 2016-01-14        32    3  2016      1         -1.0   \n",
       "2  air_ba937bf13d40fb24 2016-01-15        29    4  2016      1         -1.0   \n",
       "3  air_ba937bf13d40fb24 2016-01-16        22    5  2016      1         -1.0   \n",
       "4  air_ba937bf13d40fb24 2016-01-18         6    0  2016      1         -1.0   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors      ...        rv2_y  \\\n",
       "0         -1.0           7.0      23.843750      ...         -1.0   \n",
       "1         -1.0           2.0      20.292308      ...         -1.0   \n",
       "2         -1.0           4.0      34.738462      ...         -1.0   \n",
       "3         -1.0           6.0      27.651515      ...         -1.0   \n",
       "4         -1.0           2.0      13.754386      ...         -1.0   \n",
       "\n",
       "                                         id  total_reserv_sum  \\\n",
       "0  air_ba937bf13d40fb24_2016-01-13 00:00:00              -1.0   \n",
       "1  air_ba937bf13d40fb24_2016-01-14 00:00:00              -1.0   \n",
       "2  air_ba937bf13d40fb24_2016-01-15 00:00:00              -1.0   \n",
       "3  air_ba937bf13d40fb24_2016-01-16 00:00:00              -1.0   \n",
       "4  air_ba937bf13d40fb24_2016-01-18 00:00:00              -1.0   \n",
       "\n",
       "   total_reserv_mean  total_reserv_dt_diff_mean  date_int  var_max_lat  \\\n",
       "0               -1.0                       -1.0  20160113     8.362564   \n",
       "1               -1.0                       -1.0  20160114     8.362564   \n",
       "2               -1.0                       -1.0  20160115     8.362564   \n",
       "3               -1.0                       -1.0  20160116     8.362564   \n",
       "4               -1.0                       -1.0  20160118     8.362564   \n",
       "\n",
       "   var_max_long  lon_plus_lat  air_store_id2  \n",
       "0      4.521799    175.409667            603  \n",
       "1      4.521799    175.409667            603  \n",
       "2      4.521799    175.409667            603  \n",
       "3      4.521799    175.409667            603  \n",
       "4      4.521799    175.409667            603  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new date format\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "\n",
    "# new features for lattitude/longitude\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "# normalize id\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "\n",
    "value_col = ['holiday_flg','min_visitors','mean_visitors','median_visitors','max_visitors','count_observations',\n",
    "'rs1_x','rv1_x','rs2_x','rv2_x','rs1_y','rv1_y','rs2_y','rv2_y','total_reserv_sum','total_reserv_mean',\n",
    "'total_reserv_dt_diff_mean','date_int','var_max_lat','var_max_long','lon_plus_lat']\n",
    "\n",
    "nn_col = value_col + ['dow', 'year', 'month', 'air_store_id2', 'air_area_name', 'air_genre_name',\n",
    "'air_area_name0', 'air_area_name1', 'air_area_name2', 'air_area_name3', 'air_area_name4',\n",
    "'air_area_name5', 'air_area_name6', 'air_genre_name0', 'air_genre_name1',\n",
    "'air_genre_name2', 'air_genre_name3', 'air_genre_name4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "X_test = test[nn_col].copy()\n",
    "\n",
    "# MinMaxScaler()\n",
    "value_scaler = preprocessing.MinMaxScaler()\n",
    "for vcol in value_col:\n",
    "    X[vcol] = value_scaler.fit_transform(X[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "    X_test[vcol] = value_scaler.transform(X_test[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "\n",
    "X_train = list(X[nn_col].T.as_matrix())\n",
    "Y_train = np.log1p(X['visitors']).values\n",
    "nn_train = [X_train, Y_train]\n",
    "nn_test = [list(X_test[nn_col].T.as_matrix())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_complete_model(train, hidden1_neurons=35, hidden2_neurons=15):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        train:\n",
    "        train dataframe(used to define the input size of the embedding layer)\n",
    "        hidden1_neurons: number of neurons in the first hidden layer\n",
    "        hidden2_neurons: number of neurons in the first hidden layer\n",
    "    Output:\n",
    "        return 'keras neural network model'\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "\n",
    "    air_store_id = Input(shape=(1,), dtype='int32', name='air_store_id')\n",
    "    air_store_id_emb = Embedding(len(train['air_store_id2'].unique()) + 1, 15, input_shape=(1,),\n",
    "                                 name='air_store_id_emb')(air_store_id)\n",
    "    air_store_id_emb = keras.layers.Flatten(name='air_store_id_emb_flatten')(air_store_id_emb)\n",
    "\n",
    "    dow = Input(shape=(1,), dtype='int32', name='dow')\n",
    "    dow_emb = Embedding(8, 3, input_shape=(1,), name='dow_emb')(dow)\n",
    "    dow_emb = keras.layers.Flatten(name='dow_emb_flatten')(dow_emb)\n",
    "\n",
    "    month = Input(shape=(1,), dtype='int32', name='month')\n",
    "    month_emb = Embedding(13, 3, input_shape=(1,), name='month_emb')(month)\n",
    "    month_emb = keras.layers.Flatten(name='month_emb_flatten')(month_emb)\n",
    "\n",
    "    air_area_name, air_genre_name = [], []\n",
    "    air_area_name_emb, air_genre_name_emb = [], []\n",
    "    for i in range(7):\n",
    "        area_name_col = 'air_area_name' + str(i)\n",
    "        air_area_name.append(Input(shape=(1,), dtype='int32', name=area_name_col))\n",
    "        tmp = Embedding(len(train[area_name_col].unique()), 3, input_shape=(1,),\n",
    "                        name=area_name_col + '_emb')(air_area_name[-1])\n",
    "        tmp = keras.layers.Flatten(name=area_name_col + '_emb_flatten')(tmp)\n",
    "        air_area_name_emb.append(tmp)\n",
    "\n",
    "        if i > 4:\n",
    "            continue\n",
    "        area_genre_col = 'air_genre_name' + str(i)\n",
    "        air_genre_name.append(Input(shape=(1,), dtype='int32', name=area_genre_col))\n",
    "        tmp = Embedding(len(train[area_genre_col].unique()), 3, input_shape=(1,),\n",
    "                        name=area_genre_col + '_emb')(air_genre_name[-1])\n",
    "        tmp = keras.layers.Flatten(name=area_genre_col + '_emb_flatten')(tmp)\n",
    "        air_genre_name_emb.append(tmp)\n",
    "\n",
    "    air_genre_name_emb = keras.layers.concatenate(air_genre_name_emb)\n",
    "    air_genre_name_emb = Dense(4, activation='sigmoid', name='final_air_genre_emb')(air_genre_name_emb)\n",
    "\n",
    "    air_area_name_emb = keras.layers.concatenate(air_area_name_emb)\n",
    "    air_area_name_emb = Dense(4, activation='sigmoid', name='final_air_area_emb')(air_area_name_emb)\n",
    "    \n",
    "    air_area_code = Input(shape=(1,), dtype='int32', name='air_area_code')\n",
    "    air_area_code_emb = Embedding(len(train['air_area_name'].unique()), 8, input_shape=(1,), name='air_area_code_emb')(air_area_code)\n",
    "    air_area_code_emb = keras.layers.Flatten(name='air_area_code_emb_flatten')(air_area_code_emb)\n",
    "    \n",
    "    air_genre_code = Input(shape=(1,), dtype='int32', name='air_genre_code')\n",
    "    air_genre_code_emb = Embedding(len(train['air_genre_name'].unique()), 5, input_shape=(1,),\n",
    "                                   name='air_genre_code_emb')(air_genre_code)\n",
    "    air_genre_code_emb = keras.layers.Flatten(name='air_genre_code_emb_flatten')(air_genre_code_emb)\n",
    "\n",
    "    \n",
    "    holiday_flg = Input(shape=(1,), dtype='float32', name='holiday_flg')\n",
    "    year = Input(shape=(1,), dtype='float32', name='year')\n",
    "    min_visitors = Input(shape=(1,), dtype='float32', name='min_visitors')\n",
    "    mean_visitors = Input(shape=(1,), dtype='float32', name='mean_visitors')\n",
    "    median_visitors = Input(shape=(1,), dtype='float32', name='median_visitors')\n",
    "    max_visitors = Input(shape=(1,), dtype='float32', name='max_visitors')\n",
    "    count_observations = Input(shape=(1,), dtype='float32', name='count_observations')\n",
    "    rs1_x = Input(shape=(1,), dtype='float32', name='rs1_x')\n",
    "    rv1_x = Input(shape=(1,), dtype='float32', name='rv1_x')\n",
    "    rs2_x = Input(shape=(1,), dtype='float32', name='rs2_x')\n",
    "    rv2_x = Input(shape=(1,), dtype='float32', name='rv2_x')\n",
    "    rs1_y = Input(shape=(1,), dtype='float32', name='rs1_y')\n",
    "    rv1_y = Input(shape=(1,), dtype='float32', name='rv1_y')\n",
    "    rs2_y = Input(shape=(1,), dtype='float32', name='rs2_y')\n",
    "    rv2_y = Input(shape=(1,), dtype='float32', name='rv2_y')\n",
    "    total_reserv_sum = Input(shape=(1,), dtype='float32', name='total_reserv_sum')\n",
    "    total_reserv_mean = Input(shape=(1,), dtype='float32', name='total_reserv_mean')\n",
    "    total_reserv_dt_diff_mean = Input(shape=(1,), dtype='float32', name='total_reserv_dt_diff_mean')\n",
    "    date_int = Input(shape=(1,), dtype='float32', name='date_int')\n",
    "    var_max_lat = Input(shape=(1,), dtype='float32', name='var_max_lat')\n",
    "    var_max_long = Input(shape=(1,), dtype='float32', name='var_max_long')\n",
    "    lon_plus_lat = Input(shape=(1,), dtype='float32', name='lon_plus_lat')\n",
    "\n",
    "    date_emb = keras.layers.concatenate([dow_emb, month_emb, year, holiday_flg])\n",
    "    date_emb = Dense(5, activation='sigmoid', name='date_merged_emb')(date_emb)\n",
    "\n",
    "    cat_layer = keras.layers.concatenate([holiday_flg, min_visitors, mean_visitors,\n",
    "                    median_visitors, max_visitors, count_observations, rs1_x, rv1_x,\n",
    "                    rs2_x, rv2_x, rs1_y, rv1_y, rs2_y, rv2_y,\n",
    "                    total_reserv_sum, total_reserv_mean, total_reserv_dt_diff_mean,\n",
    "                    date_int, var_max_lat, var_max_long, lon_plus_lat,\n",
    "                    date_emb, air_area_name_emb, air_genre_name_emb,\n",
    "                    air_area_code_emb, air_genre_code_emb, air_store_id_emb])\n",
    "\n",
    "    m = Dense(hidden1_neurons, name='hidden1',\n",
    "             kernel_initializer=keras.initializers.RandomNormal(mean=0.0,\n",
    "                            stddev=0.05, seed=None))(cat_layer)\n",
    "    m = keras.layers.PReLU()(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    \n",
    "    m1 = Dense(hidden2_neurons, name='sub1')(m)\n",
    "    m1 = keras.layers.PReLU()(m1)\n",
    "    m = Dense(1, activation='relu')(m1)\n",
    "\n",
    "    inp_ten = [\n",
    "        holiday_flg, min_visitors, mean_visitors, median_visitors, max_visitors, count_observations,\n",
    "        rs1_x, rv1_x, rs2_x, rv2_x, rs1_y, rv1_y, rs2_y, rv2_y, total_reserv_sum, total_reserv_mean,\n",
    "        total_reserv_dt_diff_mean, date_int, var_max_lat, var_max_long, lon_plus_lat,\n",
    "        dow, year, month, air_store_id, air_area_code, air_genre_code\n",
    "    ]\n",
    "    inp_ten += air_area_name\n",
    "    inp_ten += air_genre_name\n",
    "    model = keras.Model(inp_ten, m)\n",
    "    model.compile(loss='mse', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214291 samples, validate on 37817 samples\n",
      "Epoch 1/3\n",
      "   256/214291 [..............................] - ETA: 46:46 - loss: 6.4243 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[17,0] = -1 is not in [0, 16)\n\t [[Node: air_genre_code_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](air_genre_code_emb/embeddings/read, _arg_air_genre_code_0_8)]]\n\nCaused by op 'air_genre_code_emb/Gather', defined at:\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-71-0b6b59fef3fc>\", line 9, in <module>\n    model4 = get_nn_complete_model(train, hidden2_neurons=12)\n  File \"<ipython-input-70-d2c419ccb060>\", line 57, in get_nn_complete_model\n    name='air_genre_code_emb')(air_genre_code)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[17,0] = -1 is not in [0, 16)\n\t [[Node: air_genre_code_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](air_genre_code_emb/embeddings/read, _arg_air_genre_code_0_8)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[17,0] = -1 is not in [0, 16)\n\t [[Node: air_genre_code_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](air_genre_code_emb/embeddings/read, _arg_air_genre_code_0_8)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-0b6b59fef3fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     model4.fit(nn_train[0], nn_train[1], epochs=3, verbose=1,\n\u001b[1;32m---> 17\u001b[1;33m         batch_size=256, shuffle=True, validation_split=0.15)\n\u001b[0m\u001b[0;32m     18\u001b[0m     model4.fit(nn_train[0], nn_train[1], epochs=8, verbose=0,\n\u001b[0;32m     19\u001b[0m         batch_size=256, shuffle=True)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[17,0] = -1 is not in [0, 16)\n\t [[Node: air_genre_code_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](air_genre_code_emb/embeddings/read, _arg_air_genre_code_0_8)]]\n\nCaused by op 'air_genre_code_emb/Gather', defined at:\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-71-0b6b59fef3fc>\", line 9, in <module>\n    model4 = get_nn_complete_model(train, hidden2_neurons=12)\n  File \"<ipython-input-70-d2c419ccb060>\", line 57, in get_nn_complete_model\n    name='air_genre_code_emb')(air_genre_code)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Chang_000\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[17,0] = -1 is not in [0, 16)\n\t [[Node: air_genre_code_emb/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](air_genre_code_emb/embeddings/read, _arg_air_genre_code_0_8)]]\n"
     ]
    }
   ],
   "source": [
    "# build models, add nn model4\n",
    "\"\"\"\n",
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, \n",
    "                      max_depth =10)\n",
    "model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "model3 = XGBRegressor(learning_rate=0.2, random_state=3, n_estimators=250, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =10)\n",
    "\"\"\"\n",
    "model4 = get_nn_complete_model(train, hidden2_neurons=12)\n",
    "\"\"\"\n",
    "model1.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model2.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model3.fit(train[col], np.log1p(train['visitors'].values))\n",
    "\"\"\"\n",
    "for i in range(5):\n",
    "    model4.fit(nn_train[0], nn_train[1], epochs=3, verbose=1,\n",
    "        batch_size=256, shuffle=True, validation_split=0.15)\n",
    "    model4.fit(nn_train[0], nn_train[1], epochs=8, verbose=0,\n",
    "        batch_size=256, shuffle=True)\n",
    "\n",
    "\"\"\"\n",
    "preds1 = model1.predict(train[col])\n",
    "preds2 = model2.predict(train[col])\n",
    "preds3 = model3.predict(train[col])\n",
    "\"\"\"\n",
    "preds4 = pd.Series(model4.predict(nn_train[0]).reshape(-1)).clip(0, 6.8).values\n",
    "\n",
    "\"\"\"\n",
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds1))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds2))\n",
    "print('RMSE XGBRegressor: ', RMSLE(np.log1p(train['visitors'].values), preds3))\n",
    "\"\"\"\n",
    "print('RMSE NeuralNetwork: ', RMSLE(np.log1p(train['visitors'].values), preds4))\n",
    "\n",
    "\"\"\"\n",
    "preds1 = model1.predict(test[col])\n",
    "preds2 = model2.predict(test[col])\n",
    "preds3 = model3.predict(test[col])\n",
    "\"\"\"\n",
    "preds4 = pd.Series(model4.predict(nn_test[0]).reshape(-1)).clip(0, 6.8).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                id   visitors\n",
      "0  air_00a91d42b08b08d9_2017-04-23   2.651837\n",
      "1  air_00a91d42b08b08d9_2017-04-24  23.447474\n",
      "2  air_00a91d42b08b08d9_2017-04-25  27.333495\n",
      "3  air_00a91d42b08b08d9_2017-04-26  26.686975\n",
      "4  air_00a91d42b08b08d9_2017-04-27  31.229905\n"
     ]
    }
   ],
   "source": [
    "# take different weights from models\n",
    "test['visitors'] = 0.15*preds1+0.15*preds2+0.3*preds3+0.4*preds4\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "#del train; del data;\n",
    "print(sub1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1[['id', 'visitors']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method : for weighted mean comparsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw data\n",
    "air_reserve = pd.read_csv('air_reserve.csv', error_bad_lines=False)\n",
    "air_store_info = pd.read_csv('air_store_info.csv', error_bad_lines=False)\n",
    "air_visit_data = pd.read_csv('air_visit_data.csv', error_bad_lines=False)\n",
    "\n",
    "hpg_reserve = pd.read_csv('hpg_reserve.csv', error_bad_lines=False)\n",
    "hpg_store_info = pd.read_csv('hpg_store_info.csv', error_bad_lines=False)\n",
    "\n",
    "date_info = pd.read_csv('date_info.csv', error_bad_lines=False)#.rename(columns={'calendar_date':'visit_date'})\n",
    "store_id_relation = pd.read_csv('store_id_relation.csv', error_bad_lines=False)\n",
    "sample_submission = pd.read_csv('sample_submission.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frames read:[]\n",
      "local variables with the same names are created.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st/code\n",
    "dfs = {re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('../input/*.csv')}\n",
    "\n",
    "print('data frames read:{}'.format(list(dfs.keys())))\n",
    "print('local variables with the same names are created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in dfs.items():\n",
    "    locals()[k] = v\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute weight of holidays\n",
    "wkend_holidays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "# merge air_visit_data & date_info\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) # cumbersome, should be better ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "print(sample_submission .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub2\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), \n",
    "    how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight sub1 / sub2\n",
    "sub_merge['visitors'] = 0.7*sub_merge['visitors_x'] + 0.3*sub_merge['visitors_y']* 1.1\n",
    "sub_merge[['id', 'visitors']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
